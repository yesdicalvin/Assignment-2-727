---
title: "Assignment 2 727"
author: "Aulia Dini & Yesdi Calvin"
date: "2023-10-03"
output:
  pdf_document: default
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

GitHub link :

https://github.com/yesdicalvin/Assignment-2-727.git


```{r, message = FALSE}
# open library
library(tidyverse)
library(gtrendsR)
library(censusapi)
library(dplyr)
library(ggplot2)
```

## **Pulling from APIs**

Our first data source is the Google Trends API. Suppose we are interested in the search trends for crime and loans in Illinois in the year 2020. We could find this using the following code:

```{r, cache=TRUE}
res <- gtrends(c("crime", "loans"), 
              geo = "US-IL", 
            time = "2020-01-01 2020-12-31", 
            low_search_volume = TRUE)

# create plot for res
plot(res)
```



### Answer the following questions for the keywords “crime” and “loans”.

### 1. Find the mean, median and variance of the search hits for the keywords.

```{r}
# change the tibble into long format
res_time_w <- pivot_wider(res$interest_over_time, 
                          names_from = keyword, 
                          values_from = hits)
head(res_time_w)
```

```{r}
# change the long format into the wide format
res_time_w <- res_time_w %>%
  pivot_longer(6:7, names_to = "keyword", values_to = "hits")
```

```{r}
# compute mean, median, var of hits
res_time_w %>%
  group_by(keyword) %>%
  summarize(mean_hits=mean(hits), 
            med_hits=median(hits),
            var_sd=var(hits))
```

Analysis :

The summary above shows some statistics descriptive of the “crime” and “loans” search popularity in Illinois from January 1, 2020, to December 31, 2020. We can see that the mean of loans hits (66.09) was higher than crime hits (54.51). There were small discrepancies between the mean and the median of loans and crime search hits, meaning there were no influential observations in the datasets. Other than that, the variance of loans hits was higher than crime hits.


### 2. Which cities (locations) have the highest search frequency for `loans`? Note that there might be multiple rows for each city if there were hits for both "crime" and "loans" in that city. It might be easier to answer this question if we had the search hits info for both search terms in two separate variables. That is, each row would represent a unique city.


```{r}
# change the data format into wide format
res_city_loans <- res$interest_by_city %>%
  pivot_wider(names_from = keyword,
              values_from= hits)%>%

# sort the data by the value of search hits of loans
arrange(desc(loans))

# print the result 
print(res_city_loans)
```

After sorting out the data in descending order, we found that the location with the highest value of hits for `loans` is Alorton, with the number of hits reaching 100, followed by Long Lake (94) and Georgetown (89). 

### 3. Is there a relationship between the search intensities between the two keywords we used?

Analysis : 

We can diagnose the relationship of search hits between these two keywords by looking at the graph of `crime` and `loans` trends. There is an inconsistent pattern between these two variables, which indicates a weak relationship. From January to September 2020 (9 months), generally, they fluctuated in different directions, indicating a negative relationship. However, for the rest (3 months), they were likely to move in the same direction, indicating a positive relationship. To make sure, we need to test it using the Pearson correlation test. 

```{r}
# compute correlation and do correlation test for  median income with coronavirus 
corr_test_res <-cor.test(res_city_loans$crime, res_city_loans$loans)
print(corr_test_res)
```
Based on the test, the correlation of search hits between `crime` and `loans` is -0.22. It means a weak and positive relationship exists between the search intensities between `crime` and `loans.` Moreover, the p-value is under the alpha (0.05). So, we do not have sufficient evidence to conclude that there is a significant relationship.

### Repeat the above for keywords related to covid. Make sure you use multiple keywords like we did above. Try several different combinations and think carefully about words that might make sense within this context.

We try to use `coronavirus` and `hospital` as keywords. 

```{r, cache=TRUE}
cov <- gtrends(c("coronavirus", "hospital"), 
               geo = "US-IL", 
               time = "2020-01-01 2020-12-31", 
               low_search_volume = TRUE)

# create plot for cov
plot(cov)
```


### 1. Compute mean, median, and variance of hits related to `coronavirus` and `hospital`.  

```{r, warning=FALSE}
# change the data format of interest over time into tibble
res_cov <- as_tibble(cov$interest_over_time)
as.numeric(res_cov$hits)

# remove the value of hits with less than 1
res_cov_sub <- subset(res_cov, hits >= 1)

# change the format of hits into numeric
res_cov_sub$hits <- as.numeric(res_cov_sub$hits)

# compute mean, median, var of hits
res_cov_sub %>%
  group_by(keyword) %>%
  summarize(mean_hits=mean(hits), 
            med_hits=median(hits),
            var_sd=var(hits))
```

Analysis:

The mean of `coronavirus` hits was significantly higher than that of hospital, with values of  16.04 and 3.94, respectively. A high discrepancy between the mean and median of `coronavirus` hits indicates the extremely high popularity of `coronavirus` searches existed at certain times. The variance of the `coronavirus` search is higher than that of the hospital, with values of 436.24 and 0.17, respectively.

### 2. Find cities with highest hits of `coronavirus`

```{r}
# change the data format into wide format
 cov_city <- cov$interest_by_city 
 cov_city <-  cov_city[!duplicated(cov_city), ] #remove duplication

  cov_city_hos <- cov_city %>%
  pivot_wider(names_from = keyword,
  values_from = hits) %>%
    
# sort the data by the value of search hits of coronavirus
arrange(desc(coronavirus))

```

```{r}
# print the result 
print(cov_city_hos)
```

Three cities with the highest coronavirus search hits in Illinois were Clarendon Hills, Gladstone, and Joy.  

### 3. Check the relationship of the search hits between `coronavirus` and `hospital`


```{r}
# compute correlation and do correlation test for  median income with coronavirus 
corr_test_cov <-cor.test(cov_city_hos$hospital, cov_city_hos$coronavirus)
print(corr_test_cov)
```
Analysis: 

The graph of coronavirus and hospital trends shows the trend of the popularity of the `coronavirus` search and `hospital` search in Illinois from January 1, 2020, to December 31, 2020. It is clearly seen that the trend of `coronavirus` search hits was different from that of `hospital` throughout the period. There was a high interest in the `coronavirus` topic from February 2020 to May 2020. The popularity of the `hospital` search was relatively stable over time. In other words, they did not have a similar pattern. The correlation between the `coronavirus` search and `hospital` search was -0.085, indicating a weak, negative, and insignificant relationship. In other words, if the `coronavirus` search increases, the search for `hospital` tends to decrease.


## **Google Trends + ACS**

Now lets add another data set. The censusapi package provides a nice R interface for communicating with this API. However, before running queries we need an access key. This (easy) process can be completed here:

https://api.census.gov/data/key_signup.html

Once you have an access key, store this key in the cs_key object. We will use this object in all following API queries.

```{r, eval=FALSE}
# get API key from getCensus
 cs_key <- "7b7f40a6d561e9e43edb14fec7e8b645055a65ed"
```

In the following, we request basic socio-demographic information (population, median age, median household income, income per capita) for cities and villages in the state of Illinois.

```{r, eval=FALSE}
# generate the data with getCensus function
acs_il <- getCensus(name = "acs/acs5",
                    vintage = 2020, 
                    vars = c("NAME", 
                             "B01001_001E", 
                             "B06002_001E", 
                             "B19013_001E", 
                             "B19301_001E"), 
                    region = "place:*", 
                    regionin = "state:17",
                    key = cs_key)
head(acs_il)
```

Convert values that represent missings to NAs.

```{r, eval=FALSE}
# convert the missing value to NA
acs_il[acs_il == -666666666] <- NA

# print the data
head(acs_il)
```

Now, it might be useful to rename the socio-demographic variables (B01001_001E etc.) in our data set and assign more meaningful names.

```{r, eval=FALSE}
# rename the column name
acs_il <-
  acs_il %>%
  rename(pop = B01001_001E, 
         age = B06002_001E, 
         hh_income = B19013_001E, 
         income = B19301_001E)
```

Then, we save the ACS data into .csv so that we don't need to generate the data repeatedly. Here, we turn of the code to create .csv file, so the data will not be replaced with new file. 

```{r}
#save the acs_il
#write.csv(acs_il, file = "C:/Users/ASUS/Documents/SURVMETH727_2/project2727part2/acs_il.csv")

#read the .csv file from directory
acs_il <- read.csv("C:/Users/ASUS/Documents/SURVMETH727_2/project2727part2/acs_il.csv")
```

```{r}
# show the dataset format
head(acs_il)
```

It seems like we could try to use this location information listed above to merge this data set with the Google Trends data. However, we first have to clean NAME so that it has the same structure as location in the search interest by city data. Add a new variable location to the ACS data that only includes city names.

```{r}
# clean name of location in the acs_il data
acs_il <- acs_il %>%
  # remove all words after certain character
  mutate(location = gsub("(.*),\\s*(.*?)\\s*$", "\\1", NAME))
  
  # remove the last word 
  acs_il$location <- sub("\\s+\\w+$", "", acs_il$location)

# check the result  
head(acs_il)
```


### Answer the following questions with the `crime` and `loans` Google trends data and the ACS data.

### 1. First, check how many cities don't appear in both data sets, i.e. cannot be matched. Then, create a new data set by joining the Google Trends and the ACS data. Keep only cities that appear in both data sets.

```{r}
# check cities in the res2 but don't appear in acs 
res2_not_in_acs <- res_city_loans %>%
  anti_join(acs_il, by = "location")

# check cities in the acs but don't appear in res2 
acs_il_not_in_res2 <- acs_il %>%
  anti_join(res_city_loans, by = "location")

# compute total cities in the res2 but don't appear in acs
count_res2_not_in_acs <- nrow(res2_not_in_acs)

# compute total cities in the acs but don't appear in res2 
count_acs_il_not_in_res2 <- nrow(acs_il_not_in_res2)

# print the result 
cat("Cities in 'res2' but not in 'acs_il':", count_res2_not_in_acs, "\n")
cat("Cities in 'acs_il' but not in 'res2':", count_acs_il_not_in_res2, "\n")
cat("Total:",count_res2_not_in_acs+count_acs_il_not_in_res2,"\n")
```

After cleaning the name and matching the location, we found that 1133 cities do not appear in both data sets. 

Below, we create a new data set by joining the Google Trends and the ACS data by keeping only cities that appear in both data sets.

```{r}
# join the data of res2 and acs with matched cities 
join_res2_acsil <- res_city_loans %>%
  inner_join(acs_il, by = "location")

# check the result
head(join_res2_acsil)
```

### 2. Compute the mean of the search popularity for both keywords for cities that have an above average median household income and for those that have an below average median household income. When building your pipe, start with creating the grouping variable and then proceed with the remaining tasks. What conclusions might you draw from this?

```{r}
# create a grouping variable based on above/below average median "hh_income"
join_res2_acsil <- join_res2_acsil %>%
  mutate(income_group = ifelse(hh_income > mean(hh_income, na.rm = TRUE),
                               "Above Average", "Below Average"))

# remove the observation with NA value of hh_income
join_res2_acsil <- join_res2_acsil[complete.cases(join_res2_acsil[, "hh_income"]), ]

# group by the "income_group" variable and calculate the mean for "crime" and "loans"
mean_bygroup <- join_res2_acsil %>%
  group_by(income_group) %>%
  summarise(
    Mean_Crime_Pop = mean(crime, na.rm = TRUE),
    Mean_Loans_Pop = mean(loans, na.rm = TRUE)
  )

# print the result
print(mean_bygroup)
```

Analysis:

Based on the information above, we can see that the average search popularity of `crime` and `loans` is higher for cities with a median household income below the average. In other words, people living in cities with median household incomes below the average searched these two keywords more frequently.

### 3. Is there a relationship between the median household income and the search popularity of the Google trends terms? Describe the relationship and use a scatterplot with qplot().

```{r, warning=FALSE}
# Create a scatterplot to visualize the relationship
sc_plot1 <- qplot(x = hh_income, y = crime, data = join_res2_acsil, 
          main = "Relationship Between hh_income and Crime Search Popularity",
          xlab = "Median Household Income", ylab = "Crime Search Popularity")

# Create a scatterplot to visualize the relationship
sc_plot2 <- qplot(x = hh_income, y = loans, data = join_res2_acsil, 
          main = "Relationship Between hh_income and loans Search Popularity",
          xlab = "Median Household Income", ylab = "loans Search Popularity")

# Print the scatterplot
print(sc_plot1)
print(sc_plot2)
```

Analysis:

Based on the scatterplot above, the plot between hh_income and `crime` and the plot between hh_income and `loans` spreads across a wider range and shows no discernible pattern. So it can be diagnosed that the hh_income variable may have an insignificant negative relationship with the frequency of searches for `loans` and  `crime`. 

```{r}
# compute correlation and do correlation test for  median income with crime 
correlation_test2 <- cor.test(join_res2_acsil$hh_income, join_res2_acsil$crime)
print(correlation_test2)

# compute correlation and do correlation test for median income with loans
correlation_test3 <- cor.test(join_res2_acsil$hh_income, join_res2_acsil$loans)
print(correlation_test3)
```

Analysis:

The result shows that the correlation coefficient between the median income and `crime` is -0.16, and it is statistically not significant. This value indicates a weak and negative relationship between the two variables. If the median income decreases, the search for `crime` tends to increases. The correlation between median income and `loans` is -0.11. This value shows a weak and negative relationship. If the median income decreases, the search for `loans` tends to increases. This relationship is statistically insignificant. 

### Repeat the above steps using the covid data and the ACS data.

### 1. Check how many cities don't appear in both data sets

```{r}
# check cities in the cov_city_hos but don't appear in acs 
cov2_not_in_acs <- cov_city_hos %>%
  anti_join(acs_il, by = "location")

# check cities in the acs but don't appear in cov_city_hos 
acs_il_not_in_cov2 <- acs_il %>%
  anti_join(cov_city_hos, by = "location")

# compute total cities in the cov_city_hos but don't appear in acs
count_cov2_not_in_acs <- nrow(cov2_not_in_acs)

# compute total cities in the acs but don't appear in cov_city_hos 
count_acs_il_not_in_cov2 <- nrow(acs_il_not_in_cov2)

# print the result 
cat("Cities in 'cov2' but not in 'acs_il':", count_cov2_not_in_acs, "\n")
cat("Cities in 'acs_il' but not in 'cov2':", count_acs_il_not_in_cov2, "\n")
cat("Total:",count_cov2_not_in_acs+count_acs_il_not_in_cov2,"\n")
```

Here, we found 1125 cities that do not appear in both data sets. 

Below, we create a new data set by joining the Google Trends and the ACS data by keeping only cities that appear in both data sets.

```{r}
# join the data of cov_city_hos and acs with matched cities 
join_cov2_acsil <- cov_city_hos %>%
  inner_join(acs_il, by = "location")

# check the result
head(join_cov2_acsil)
```

### 2. Compute the mean of the search popularity for both keywords for cities that have an above average median household income and for those that have an below average median household income. 

```{r}
# create a grouping variable based on above/below average median "hh_income"
join_cov2_acsil <- join_cov2_acsil %>%
  mutate(income_group = ifelse(hh_income > mean(hh_income, na.rm = TRUE),
                               "Above Average", "Below Average"))

# remove the observation with NA value of hh_income
join_cov2_acsil <- join_cov2_acsil[complete.cases(join_cov2_acsil[, "hh_income"]), ]

# group by the "income_group" variable and calculate the mean for "coronavirus" and "hospital"
mean_bygroup <- join_cov2_acsil %>%
  group_by(income_group) %>%
  summarise(
    Mean_Coronavirus_Pop = mean(coronavirus, na.rm = TRUE),
    Mean_Hospital_Pop = mean(hospital, na.rm = TRUE)
  )

# print the result
print(mean_bygroup)
```

Analysis :

Based on the table above, we can see that the average search for `coronavirus` is higher for cities with a median household income above the average. However, the average search for `hospital` is higher for cities with a median household income below average. 

### 3. Check the relationship between the median household income and the search popularity of the Google trends terms. Describe the relationship and use a scatterplot with `qplot()`.

```{r, warning=FALSE}
# Create a scatterplot to visualize the relationship
sc_plot1 <- qplot(x = hh_income, y = coronavirus, data = join_cov2_acsil, 
          main = "Relationship Between hh_income and Coronavirus Search Popularity",
          xlab = "Median Household Income", ylab = "Coronavirus Search Popularity")

# Create a scatterplot to visualize the relationship
sc_plot2 <- qplot(x = hh_income, y = hospital, data = join_cov2_acsil, 
          main = "Relationship Between hh_income and Hospital Search Popularity",
          xlab = "Median Household Income", ylab = "Hospital Search Popularity")

# Print the scatterplot
print(sc_plot1)
print(sc_plot2)
```
Analysis: 

The scatter plot shows a slightly increasing pattern between hh_income and the `coronavirus` popularity search. The distribution of hh_income was concentrated from 0 to 75,000. In brief, we can diagnose that there is a positive and significant relationship between these two variables. The scatterplot between search hits of `hospital` and hh_income shows a linear pattern with some extreme values. 

```{r}
# compute correlation and do correlation test for  median income with coronavirus 
correlation_test2<-cor.test(join_cov2_acsil$hh_income, join_cov2_acsil$coronavirus)
print(correlation_test2)

# compute correlation and do correlation test for median income with hospital
correlation_test3<-cor.test(join_cov2_acsil$hh_income, join_cov2_acsil$hospital)
print(correlation_test3)
```
Analysis:

The correlation between hh_income and `coronavirus` confirms this finding with a value of 0.33. This correlation score means that the search hits for `coronavirus` have a weak, positive, and significant relationship with hh_income. If the hh_income increases, the value of search hits of `coronavirus` also increases. The correlation coefficient between hh_income and `hospital` is insignificant, with a value of -0.05, which means there is not any significant relationship between search hits of `hospital` and the hh_income.

